{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1041cf2f",
   "metadata": {},
   "source": [
    "# **Evaluating RAG Applications with Ragas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cc35c",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to evaluate Retrieval-Augmented Generation (RAG) applications using the Ragas framework. We will install the necessary libraries, test each metric individually, and evaluate all metrics on a sample dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc74dfd",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- Install Libraries\n",
    "- Setup\n",
    "- Test Metrics Individually\n",
    "- Evaluate Full Datasets\n",
    "- Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adbcb2a",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1107c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af494f09",
   "metadata": {},
   "source": [
    "In this example, weâ€™ll use:\n",
    "\n",
    "ðŸ”¹ Groq as the LLM â€” fast and free with an API key\n",
    "\n",
    "ðŸ”¹ Hugging Face for embeddings â€” lightweight and open-source\n",
    "\n",
    "These are used to compute Ragas scores, where the LLM evaluates answer quality and embeddings handle semantic similarity for retrieval metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbff456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "import  os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"gsk_***\"\n",
    "\n",
    "llm_groq = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    ")\n",
    "\n",
    "llm = LangchainLLMWrapper(llm_groq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a923a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "EMBEDDING_MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "embeddings_hf = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_kwargs={\"device\": \"cuda\"}\n",
    ")\n",
    "\n",
    "embeddings = LangchainEmbeddingsWrapper(embeddings_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e3425",
   "metadata": {},
   "source": [
    "## Test Metrics Individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6fd65b",
   "metadata": {},
   "source": [
    "### Context Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b25131",
   "metadata": {},
   "source": [
    "LLM-Based Context Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add39b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import LLMContextPrecisionWithoutReference\n",
    "\n",
    "context_precision = LLMContextPrecisionWithoutReference(llm=llm)\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "   user_input=\"Where is the Eiffel Tower located?\",\n",
    "   response=\"The Eiffel Tower is located in Paris.\",\n",
    "   retrieved_contexts=[\"The Eiffel Tower is located in Paris.\"], \n",
    ")\n",
    "\n",
    "await context_precision.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090738c",
   "metadata": {},
   "source": [
    "Non LLM-Based Context Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd95ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import NonLLMContextPrecisionWithReference\n",
    "\n",
    "context_precision = NonLLMContextPrecisionWithReference()\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    retrieved_contexts=[\"The Eiffel Tower is located in Paris.\"], \n",
    "    reference_contexts=[\"Paris is the capital of France.\", \"The Eiffel Tower is one of the most famous landmarks in Paris.\"]\n",
    ")\n",
    "\n",
    "await context_precision.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e43aadc",
   "metadata": {},
   "source": [
    "### Context Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9ddbd",
   "metadata": {},
   "source": [
    "LLM-Based Context Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c61054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import LLMContextRecall\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    user_input=\"Where is the Eiffel Tower located?\",\n",
    "    response=\"The Eiffel Tower is located in Paris.\",\n",
    "    reference=\"The Eiffel Tower is located in Paris.\",\n",
    "    retrieved_contexts=[\"Paris is the capital of France.\"], \n",
    ")\n",
    "\n",
    "context_recall = LLMContextRecall(llm=llm)\n",
    "await context_recall.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ff86f",
   "metadata": {},
   "source": [
    "Non LLM-Based Context Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43180411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import NonLLMContextRecall\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    retrieved_contexts=[\"Paris is the capital of France.\"], \n",
    "    reference_contexts=[\"Paris is the capital of France.\", \"The Eiffel Tower is one of the most famous landmarks in Paris.\"]\n",
    ")\n",
    "\n",
    "context_recall = NonLLMContextRecall()\n",
    "await context_recall.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4331a990",
   "metadata": {},
   "source": [
    "### Faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample \n",
    "from ragas.metrics import Faithfulness\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "        user_input=\"When was the first super bowl?\",\n",
    "        response=\"The first superbowl was held on Jan 15, 1967\",\n",
    "        retrieved_contexts=[\n",
    "            \"The First AFLâ€“NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles.\"\n",
    "        ]\n",
    "    )\n",
    "scorer = Faithfulness(llm=llm)\n",
    "\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c5c4d",
   "metadata": {},
   "source": [
    "### Answer Relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample \n",
    "from ragas.metrics import ResponseRelevancy\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "        user_input=\"When was the first super bowl?\",\n",
    "        response=\"The first superbowl was held on Jan 15, 1967\",\n",
    "        retrieved_contexts=[\n",
    "            \"The First AFLâ€“NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles.\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "scorer = ResponseRelevancy(llm=llm, embeddings=embeddings)\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43733647",
   "metadata": {},
   "source": [
    "## Evaluate Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "data_samples = {\n",
    "    'question': [\n",
    "        \"When was Soekarno born?\",\n",
    "        \"What is Pancasila?\",\n",
    "        \"Where is Mount Bromo located?\",\n",
    "        \"When did Indonesia gain independence?\",\n",
    "        \"What is the capital city of Indonesia?\"\n",
    "    ],\n",
    "    'answer': [\n",
    "        \"Soekarno was born on June 6, 1901.\",\n",
    "        \"Pancasila is the foundation of Indonesia.\",\n",
    "        \"Mount Bromo is located in East Java, Indonesia.\",\n",
    "        \"Indonesia declared independence in 1945.\",\n",
    "        \"Jakarta is the capital city of Indonesia.\"\n",
    "    ],\n",
    "    'contexts': [\n",
    "        [\"Soekarno, the first President of Indonesia, was born on June 6, 1901, in Surabaya.\"],\n",
    "        [\"Pancasila is the philosophical foundation of the Indonesian state, consisting of five principles introduced by Sukarno in 1945.\"],\n",
    "        [\"Mount Bromo is an active volcano situated in East Java, Indonesia, and is part of the Tengger massif.\"],\n",
    "        [\"Indonesia proclaimed its independence from Dutch colonial rule on August 17, 1945, following the end of World War II.\"],\n",
    "        [\"Jakarta is the current capital city of Indonesia, located on the northwest coast of the island of Java.\"]\n",
    "    ],\n",
    "\n",
    "    # Optional, but required for evaluating context precision or context recall\n",
    "    'ground_truth': [\n",
    "        \"June 6, 1901\",\n",
    "        \"The philosophical foundation of the Indonesian state consisting of five principles.\",\n",
    "        \"East Java, Indonesia\",\n",
    "        \"August 17, 1945\",\n",
    "        \"Jakarta\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    ")\n",
    "\n",
    "score = evaluate(\n",
    "    dataset,\n",
    "    llm=llm,\n",
    "    embeddings=embeddings,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ]\n",
    ")\n",
    "df = score.to_pandas()\n",
    "df.to_csv('result/score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e660fa",
   "metadata": {},
   "source": [
    "## Notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d5ffe",
   "metadata": {},
   "source": [
    "- **Model Initialization**: Make sure to initialize your RAG model before running the evaluation metrics. You may need to load a pre-trained model or define your own.\n",
    "- **Ragas Methods**: Ensure that the methods used in the Ragas framework (like `evaluate_faithfulness`, `evaluate_relevancy`, etc.) are correctly named according to the actual implementation in the library.\n",
    "- **Results Interpretation**: In the conclusion section, you can summarize the findings based on the scores obtained from the metrics.\n",
    "\n",
    "This structure should help you create a comprehensive Jupyter Notebook that aligns with the content of your article while providing a clear and organized evaluation process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
